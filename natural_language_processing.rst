======================
正規表現と自然言語処理
======================

.. contents:: :depth: 3

.. seealso::

   :title-reference:`Introduction to Information Retrieval`

      chapter 2
      chapter 3
      chapter 6

動機付け
========

情報検索は、集めたオブジェクトから特徴量を抽出し、得られた特徴から検索用のインデックスを作成します。例えば今回の作成しているWeb検索システムの場合、クローラが集めたWebページが検索対象オブジェクトとなり、それぞれのページに記述されているテキストや埋めこまれている画像、メタデータなどがコンテンツとなります。そして、それらのコンテンツから、時間表現や単語頻度、画像ヒストグラムなどを特徴量として抽出できます。

このように、あるオブジェクトから特徴を抽出し、それをベクトルとして表現したものを、このオブジェクトの **特徴ベクトル** と呼びます。特徴ベクトルを用いた検索については、「文書の検索」の回で改めて解説します。

今回扱う正規表現と自然言語処理は、テキストコンテンツから特徴量を抽出するのに用いることができます。例えば次のような文書があったとしましょう。::

  Python(パイソン)は、オランダ人のグイド・ヴァンロッサムが作った
  オープンソースのプログラミング言語。
  
  最新リリース
  3.2 / 2011年2月20日

このような文書から

   時間表現の抽出
       2011年2月20日

   単語(名詞)の抽出
       Python、パイソン、オランダ人、グイド・ヴァンロッサム、オープンソース、プログラミング、言語

のような特徴を抽出できるようにすることが、今回の目標です。

正規表現
========

正規表現とは文字列のパターンを表現する表記法のことで、マッチする文字列を直接指定せず、パターンを指定することで、表記ゆれを吸収しての操作が可能となります。正規表現は多くのプログラミング言語で実装されていますが、それぞれの実装内容が微妙に異なっています。今回は、多くの正規表現実装に共通して用いられているメタ文字について触れ、Pythonで正規表現を提供するreモジュールの使い方について説明します。

メタ文字
--------

正規表現を理解するのに良いWebアプリ
-----------------------------------

#. RegExr

   正規表現は実際に記述しなければ理解することが難しいので、自分で試してみることが重要でが、毎回毎回Pythonのreモジュールを使って試すのは大変ですし、時間もかかります。
   
   RegExrは入力した正規表現の適合箇所を簡単に確認することができるWebアプリケーションです。
   上のテキストボックスに正規表現を入力すると、下の文書の中でそれにマッチする箇所を表示してくれるので、トライアンドエラーのサイクルが短くすることができます。
   
   プログラムを書く前に、意図した通りに表現できているかを確かめる用途にも使うことができます。
   
   URL: http://www.gskinner.com/RegExr/
   
   .. image:: /images/RegExr.png

#. strfriend

   正規表現は理論的にはオートマトンを用いて説明することができます。
   
   strfriendは入力された正規表現を表す非決定性オートマトンを出力してくれるWebアプリケーションです。
   これを用いて正規表現を可視化することで、複雑で難しい正規表現が理解しやすくなるかも知れません。
   
   URL: http://www.strfriend.com/
   
   .. image:: /images/strfriend1.png
   
   メールアドレスにマッチする正規表現を入力した場合
   
   .. image:: /images/strfriend2.png

Pythonでの使用法
----------------

.. seealso::

   Python公式ドキュメント
      `7.2. re - 正規表現操作 <http://www.python.jp/doc/nightly/library/re.html>`_

#. マッチするものを全て列挙する場合、findallを使います。::

       >>> import re
       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> re.findall('\w+', text)
       ['python', 'lightweight', 'programming']

   findallはグループにも対応しています。::

       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> re.findall('(\w+)とは(\w+)', text)
       [('python', 'lightweight')]

   グループが邪魔な場合は(?:...)の様に、?:をグループの最初につけます。::

      >>> re.findall('(?:\w+)とは(?:\w+)', text)
      ['python\xe3\x81\xa8\xe3\x81\xaflightweight']

#. マッチ部分に対応するMatchObjectを取得したい場合は、finditerを使います。::

       >>> import re
       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> for mo in re.finditer('(\w+)とは(\w+)', text)
       ...     print mo.group(0)
       ...     print mo.group(1)
       ...     print mo.group(2)
       ...
       pythonとはlightweight
       python
       lightweight

   MatchObjectは名前付きのグループを使った時に特に便利です。次のようにgroupdictを使うことで、グループ名をキーとした辞書が返されます。::

       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> re.findall('(?P<first>\w+)とは(?P<second>\w+)', text)
       [('python', 'lightweight')]
       >>> for mo in re.finditer(pattern, text):
       ...     print mo.groupdict()
       ...
       {'first': 'python', 'second': 'lightweight'}

   例えば日付表現を抽出する場合、次のように名前付きグループを作ることで、マッチした箇所の抽出するプログラムの可読性を高めることができます。::

       >>> pattern = '(?P<year>[1-9]\d{1,3})年(?P<month>1[0-2]|[1-9])月(?P<day>3[01]|[12]\d|[1-9])日'
       >>> text = '''リリース
       ... 3.2/ 2011年2月20日
       ... 2.7.1/ 2010年11月27日
       ... '''
       >>> for mo in re.finditer(pattern, text):
       ...    # mo.group(2)と比べて月を抽出していることが明確になる。
       ...    print mo.groupdict()['month']
       ...
       2
       11

#. 文字列を先頭から順番に見ていき、正規表現にマッチする最初の箇所が欲しい場合はsearchを使います。searchの返り値はMatchObjectなので、groupdictを利用することができます。::

       >>> import re
       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> mo = re.search('l\w+', text)
       >>> print s.group()
       lightweight

#. 文字列が先頭から正規表現にマッチしているかを知りたい場合はmatchを使います。::

       >>> import re
       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> re.match('l\w+', text) # 先頭はlで始まらない
       None
       >>> print re.match('\w+', text).group()
       python

   逆にmatchを使うと暗黙的に文字列の先頭からを意味することになるので、注意して下さい。

#. 正規表現パターンから正規表現オブジェクトに変換するのは時間のかかる処理です。そのため、繰り返し利用される正規表現パターンはcompileを使うことで、正規表現オブジェクトを再利用することができます。::

       >>> import re
       >>> regex = re.compile('\w+')  # regexを繰り返し再利用することができる
       >>> text = 'pythonとはlightweightな、programming言語である'
       >>> regex.findall(text)
       ['python', 'lightweight', 'programming']

   ただし、re.match(), re.search(), re.compile()は渡された最後の物がキャッシュとして残るので、正規表現パターンが1種類しかでてこない場合は、compileを利用する必要はありません。

#. 複数行にまたがる文字列に対し、各行の行頭や(各改行の直後)や行末(改行の直前)にマッチさせたい場合、re.MULTILINEオプションを指定した上で、^や$を使います。::

       >>> import re
       >>> pattern = '^\w+'
       >>> text = '''python
       ... パイソン
       ... ルビー ruby
       ... perl
       ... C言語
       ... '''
       >>> re.findall(pattern, text, re.MULTILINE)
       ['python', 'perl', 'C']
       >>> re.findall(pattern, text, re.M)  # re.MでもOK
       ['python', 'perl', 'C']

   逆に、re.MULTILINEをつけ忘れると、^と$は文字列の最初と最後にのみマッチするようになります。::

       >>> re.findall('^\w+', text)
       ['python']


自然言語処理
============

概要
----

形態素解析・正規化
------------------

Pythonでの使用法
----------------

課題
====

課題1 ex1_re.py
---------------

1. 与えられた文字列から **時間表現を抽出** する関数(ex11)を作成せよ。

   この課題での時間表現とは *時分秒* を表し、次の形式のいずれかとする。

   A. 1:12:13
      時分秒は:で区切られる 1時12分13秒
   B. 01:12:13
      0による桁あわせ
   C. 01:12:13 pm
      12時間表記 半角スペース1個の後にpmもしくはam
   D. 01:12:13 p.m.
      12時間表記 半角スペース1個の後にp.m.もしくはa.m.
   
   **注意点**
   
   * 0時0分0秒から23時59分59秒の間のみ抽出する
     99:99:99のような表現は抽出しない
   * 14:00:00 p.m. のような表現は抽出しない
   * HWaddr 00:23:54:91:03:09 のような表現は抽出しない
   * すべてを正規表現で行う必要はない
     正規表現で時間表現の候補を抽出 -> 無効な表現を削除

2. 与えられた文字列から時間表現を抽出し、それらを **hh:mm:ss形式に正規化** する関数(ex12)を作成せよ。

   A. 1:12:13       -> 01:12:13
   B. 01:12:13 p.m. -> 13:12:13

次のコードをex1_re.pyという名前で保存し、テストが通るように実装する::

   # -*- coding: utf-8 -*-
   
   
   def ex11(text):
       '''課題1-1
       引数の文字列(text)から時間表現を抽出する。
   
           >>> ex11('1:2:3 to 1:3:3')
           ['01:02:03', '01:03:03']
           >>> ex11('updated at 0:00:00')
           ['0:00:00']
           >>> ex11('11:15:30 pm')
           ['11:15:30 pm']
           >>> ex11('11:15:30 am')
           ['11:15:30 am']
           >>> ex11('11:15:30 p.m.')
           ['11:15:30 p.m.']
           >>> ex11('11:15:30 a.m.')
           ['11:15:30 a.m.']
           >>> ex11('12:23:34 pmi conference ...')
           ['12:23:34']

       Macアドレスなどに反応してはいけない。

           >>> ex11('2011:05:17')
           []
           >>> ex11('HWaddr 00:23:54:91:03:05')
           []
           >>> ex11('23:11: ')
           []
           >>> ex11('12:234:56')
           []
           >>> ex11('14:00:00 pm')
           []
           >>> ex11('24:00:00')
           []
           >>> ex11('99:99:99')
           []
       '''
       pass
   
   
   if __name__ == '__main__':
       import doctest
       doctest.testmod()

テストは次のようにすることで実行できる::

   $ python ex1_re.py

課題2 ex2_nlp.py
----------------

1. 与えられた単語が **ストップワードであるかどうかを判別** する関数(ex21)を作成せよ。

   * 何がストップワードであるかは好きに決めていい
   * SlothLibのストップワードリストを使用してもいい
   * nltkのストップワードリスト(英語のみ利用可能)を使用してもいい

2. 与えられた文字列（日本語ベース）を **形態素解析し、名詞のみを抽出し、正規化し、ストップワードを除去した後、単語の出現回数をカウントしたディクショナリ** を作成する関数(ex22)を作成せよ。

      例えば::

         Database (<複> databases)とは、特定のテーマに沿ったデータを集めて管理し、
         容易に検索・抽出などの再利用をできるようにしたもの。

      という文字列が入力された場合::

         {"複": 1, "データ": 1, "管理": 1, "再": 1, "抽出": 1, "database": 2,
          "特定": 1, "検索": 1, "テーマ": 1, "容易": 1, "利用": 1}

次のコードをex2_nlp.pyという名前で保存し、テストが通るように実装する。::

   # -*- coding: utf-8 -*-
   
   
   def ex21(word):
       '''課題2-1
       引数の文字列(word)がストップワードであればTrueを返す
   
           >>> ex21("こと")
           True
           >>> ex21("データベース")
           False
           >>> ex21("the")
           True
           >>> ex21("database")
           False
       '''
       pass
   
   
   def ex22(text):
       '''課題2-2
       引数の文字列(text)から名詞を抽出し、正規化、 ストップワードを除去する。
       その後、単語の出現頻度をカウントしたディクショナリを返す。
       下記はあくまでも一例
   
           >>> text = """Database (<複> databases)とは、
           ... 特定のテーマに沿ったデータを集めて管理し、
           ... 容易に検索・抽出などの再利用をできるようにしたもの。"""
           >>> tf = ex22(text)
           >>> for key in sorted(tf.keys()):
           ...     print key, tf[key]
           ...
           database 2
           テーマ 1
           データ 1
           再 1
           利用 1
           容易 1
           抽出 1
           検索 1
           特定 1
           管理 1
           複 1

       ここで得られた辞書型オブジェクトtfのように、ベクトルの各次元が単語の文書中での
       出現回数となっているものをterm frequencyベクトルという。
       多くの場合、省略して単にtfベクトルとも呼ばれる。
       '''
       pass
   
   if __name__ == '__main__':
       import doctest
       doctest.testmod()

テストは次のようにすることで実行できる::

   $ python ex2_nlp.py
